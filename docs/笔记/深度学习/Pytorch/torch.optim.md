# `torch.optim`

[TOC]

## `torch.optim.SGD`

### 类声明：

> `torch.optim.SGD(params, lr=<required parameter>, momentum=0, dampening=0, weight_decay=0, nesterov=False, *, maximize=False, foreach=None, differentiable=False)`

