# 机器学习

[TOC]

## 减少过拟合的方式

- 权重衰减：权重衰减是指在更新损失函数梯度的时候在对参数项添加一个衰减因子，从原理上权重衰减等价于损失函数的L2正则化。
- 正则化：正则化相比权重衰减更加一般。
- 暂退法（dropout）
- 早停

## 为什么可以选择交叉熵损失作为分类问题的损失函数

1.数学性质:交叉嫡是一个广泛应用于信息论和机器学习中的概念，具有良好的数学性质。它是一个非负函数，当且仅当两个概率分布完全相同时取得最小值。因此，使用交叉嫡作为损失函数可以帮助模型更好地拟合训练数据。

⒉.最大似然估计:交叉嫡损失函数可以与最大似然估计(Maximum Likelihood Estimation）相联系。在分类任务中，我们希望模型的输出概率分布能够尽可能地接近真实标签的分布。最大化似然函数等价于最小化交叉嫡损失函数，因此使用交叉嫡可以优化模型的分类性能。

3.梯度下降优化:交叉嫡损失函数对于梯度下降优化算法来说具有良好的可导性质。梯度下降是一种常用的优化算法，通过计算损失函数对模型参数的梯度来更新参数值，使得损失函数逐渐减小。交叉嫡损失函数的梯度计算相对简单，能够有效地指导模型参数的更新。

4.类别不平衡问题:在分类任务中，不同类别的样本数量可能存在不平衡。交叉嫡损失函数对于不同类别的样本有不同的权重，可以更好地处理类别不平衡问题。它能够让模型更关注少数类别的样本，从而提高整体分类性能。